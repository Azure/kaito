apiVersion: v1
kind: Pod
metadata:
  annotations:
  name: demo-2gpu
  namespace: default
  labels:
    app: llama
spec:
  containers:
  - command:
    - sleep
    - infinity
    image: aimodelsregistry.azurecr.io/llama-2-13b-chat:latest
    name: main
    resources:
      limits:
        nvidia.com/gpu: 2
      requests:
        nvidia.com/gpu: 2
    volumeMounts:
    - name: dshm
      mountPath: /dev/shm
  volumes:
  - name: dshm
    emptyDir:
      medium: Memory
  # nodeSelector:
  #   kubernetes.io/hostname: gpu_machine_here
  tolerations:
  - effect: NoSchedule
    key: sku
    operator: Equal
    value: gpu
  - effect: NoSchedule
    key: nvidia.com/gpu
    operator: Exists
