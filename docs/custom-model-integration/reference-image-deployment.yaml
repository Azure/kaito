apiVersion: kaito.sh/v1alpha1
kind: Workspace
metadata:
  name: workspace-custom-llm
resource:
  instanceType: "Standard_NC12s_v3" # Replace with the required VM SKU based on model requirements
  labelSelector:
    matchLabels:
      apps: custom-llm
inference:
  template: 
    spec:
      containers:
      - name: custom-llm-container
        image: ghcr.io/azure/kaito/llm-reference-preset:latest
        command: ["accelerate"]
        args: 
          - "launch"
          - "--num_processes"
          - "1"
          - "--num_machines"
          - "1"
          - "--gpu_ids"
          - "all"
          - "inference_api.py"
          - "--pipeline"
          - "text-generation"
          - "--trust_remote_code"
          - "--allow_remote_files"
          - "--pretrained_model_name_or_path"
          - "<MODEL_ID>"  # Replace <MODEL_ID> with the specific HuggingFace model identifier
          - "--torch_dtype"
          - "float16"  # Set to "float16" for compatibility with V100 GPUs; use "bfloat16" for A100, H100 or newer GPUs
        volumeMounts:
        - name: dshm
          mountPath: /dev/shm
      volumes:
      - name: dshm
        emptyDir:
          medium: Memory