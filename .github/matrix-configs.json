[
    {
        "model": {
            "runs_on": "self-hosted",
            "name": "falcon-7b",
            "dockerfile": "docker/presets/tfs/Dockerfile",
            "build_args": "--build-arg MODEL_NAME=tiiuae/falcon-7b"
        },
        "shouldBuildFalcon": "true"
    },
    {
        "model": {
            "runs_on": "self-hosted",
            "name": "falcon-7b-instruct",
            "dockerfile": "docker/presets/tfs/Dockerfile",
            "build_args": "--build-arg MODEL_NAME=tiiuae/falcon-7b-instruct"
        },
        "shouldBuildFalcon": "true"
    },
    {
        "model": {
            "runs_on": "self-hosted",
            "name": "falcon-7b-instruct",
            "dockerfile": "docker/presets/tfs-onnx/Dockerfile",
            "build_args": "--build-arg MODEL_NAME=tiiuae/falcon-7b-instruct"
        },
        "shouldBuildFalcon": "true"
    },
    {
        "model": {
            "runs_on": "self-hosted",
            "name": "falcon-40b",
            "dockerfile": "docker/presets/tfs/Dockerfile",
            "build_args": "--build-arg MODEL_NAME=tiiuae/falcon-40b"
        },
        "shouldBuildFalcon": "true"
    },

    {
        "model": {
            "runs_on": "self-hosted",
            "name": "falcon-40b-instruct",
            "dockerfile": "docker/presets/tfs/Dockerfile",
            "build_args": "--build-arg MODEL_NAME=tiiuae/falcon-40b-instruct"
        },
        "shouldBuildFalcon": "true"
    },

    {
        "model": {
            "runs_on": "self-hosted",
            "name": "llama-2-7b",
            "dockerfile": "docker/presets/llama-2/Dockerfile",
            "build_args": "--build-arg LLAMA_WEIGHTS=/llama/llama-2-7b --build-arg SRC_DIR=/home/presets/llama-2"
        },
        "shouldBuildLlama2": "true"
    },

    {
        "model": {
            "runs_on": "self-hosted",
            "name": "llama-2-13b",
            "dockerfile": "docker/presets/llama-2/Dockerfile",
            "build_args": "--build-arg LLAMA_WEIGHTS=/llama/llama-2-13b --build-arg SRC_DIR=/home/presets/llama-2"
        },
        "shouldBuildLlama2": "true"
    },

    {
        "model": {
            "runs_on": "self-hosted",
            "name": "llama-2-70b",
            "dockerfile": "docker/presets/llama-2/Dockerfile",
            "build_args": "--build-arg LLAMA_WEIGHTS=/llama/llama-2-70b --build-arg SRC_DIR=/home/presets/llama-2"
        },
        "shouldBuildLlama2": "true"
    },

    {
        "model": {
            "runs_on": "self-hosted",
            "name": "llama-2-7b-chat",
            "dockerfile": "docker/presets/llama-2/Dockerfile",
            "build_args": "--build-arg LLAMA_WEIGHTS=/llama/llama-2-7b-chat --build-arg SRC_DIR=/home/presets/llama-2-chat"
        },
        "shouldBuildLlama2Chat": "true"
    },

    {
        "model": {
            "runs_on": "self-hosted",
            "name": "llama-2-13b-chat",
            "dockerfile": "docker/presets/llama-2/Dockerfile",
            "build_args": "--build-arg LLAMA_WEIGHTS=/llama/llama-2-13b-chat --build-arg SRC_DIR=/home/presets/llama-2-chat"
        },
        "shouldBuildLlama2Chat": "true"
    },

    {
        "model": {
            "runs_on": "self-hosted",
            "name": "llama-2-70b-chat",
            "dockerfile": "docker/presets/llama-2/Dockerfile",
            "build_args": "--build-arg LLAMA_WEIGHTS=/llama/llama-2-70b-chat --build-arg SRC_DIR=/home/presets/llama-2-chat"
        },
        "shouldBuildLlama2Chat": "true"
    }
]
